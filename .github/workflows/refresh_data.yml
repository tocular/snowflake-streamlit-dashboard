name: Refresh Dashboard Data

on:
  schedule:
    # Run on the 1st of each month at midnight UTC
    - cron: '0 0 1 * *'
  workflow_dispatch:

jobs:
  refresh:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install nbconvert ipykernel

      - name: Execute data refresh notebook
        env:
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
          SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
        run: |
          jupyter nbconvert --to notebook --execute dashboard.ipynb --output dashboard_executed.ipynb
          rm dashboard_executed.ipynb

      - name: Check for anomalies and send alerts
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: python alerts.py

      - name: Commit updated data files
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add tables/*.csv tables/*.csv.gz

          # Only commit if there are changes
          if git diff --staged --quiet; then
            echo "No data changes detected"
          else
            git commit -m "Refresh dashboard data [automated]"
            git push
          fi
